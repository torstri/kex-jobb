\documentclass{kththesis}

\usepackage{blindtext} % This is just to get some nonsense text in this template, can be safely removed

\usepackage{csquotes} % Recommended by biblatex
\usepackage[style=numeric,sorting=none,backend=biber]{biblatex}
\addbibresource{references.bib} % The file containing our references, in BibTeX format

\title{This is the English title}
\alttitle{Detta är den svenska översättningen av titeln}
\author{Vilmer Jonsson \\ Tor Strimbold}
\supervisor{Kevin Smith}
\examiner{Pawel Herman} 
\programme{Bachelor in Computer Science}
\school{School of Electrical Engineering and Computer Science}
\date{\today}

% Uncomment the next line to include cover generated at https://intra.kth.se/kth-cover?l=en
\kthcover{kth-cover.pdf} % Cover page background file, placeholder for now


\begin{document}

% Frontmatter includes the titlepage, abstracts and table-of-contents
\frontmatter

\titlepage

\begin{abstract}
  English abstract goes here.

  \blindtext
\end{abstract}


\begin{otherlanguage}{swedish}
  \begin{abstract}
    abstract på svenska.
  \end{abstract}
\end{otherlanguage}


\tableofcontents


% Mainmatter is where the actual contents of the thesis goes
\mainmatter


% TODO: Fix the references
\chapter{Introduction}
The frequency of malignant melanoma has in the last decade been on the rise with approximately 60 000 people being diagnosed with the disease yearly \parencite{sverige-hudcancer}.
A similar trend has been observed in the United States where the frequency of people diagnosed with the disease has doubled yearly from 1982-2011 \parencite{aad-skin-cancer}.

% TODO: Fix the references, could not find the source in Drive
Skin cancer, although common, has a survival rate of up to 95\% if discovered at an early stage. %(källa)
This fact makes the diagnosis of malignant melanoma an essential part of the treatment of the disease. In the light of diagnosis, machine learning has become a subject of interest in many medical fields, dermatology included. Multiple studies have been conducted to evaluate the potential of the algorithms’ accuracy and applicability through so called computer aided diagnostics (CAD). Concerning malignant melanoma, some studies have reached an accuracy of up to 90\% which competes with the experts in the field. %(källa). 

The accuracy of machine learning algorithms is however heavily reliant on the feature extraction methods used, where relevant features in an image are extracted and then used in the classification of the skin lesion. An effective feature extraction in turn relies on determining which features to use. Which is the subject of feature selection where different features are compared in terms of their effect on the diagnostic accuracy. It has been shown that effective feature selection make classifiers more effective, accurate and cost-effective. \parencite{KarabulutEsraMahsereci2012Acso}

\section{Research Question}
In our thesis we will study the effect of two different feature selection methods upon 169 features and using 4 different machine learning models. We aim to answer:
\begin{enumerate}
    \item Which features and combinations of features are the most important in terms of classification accuracy?
    \item Is there a difference between different models concerning which features are most effective?
    \item Are some feature selection methods more efficient in creating better accuracy than others? Which one uses the fewest number of features?
  
\end{enumerate}

\section{Approach}

To study the proposed research questions both forward and backwards selection will be performed. To further widen the base for comparison four different machine learning models will be used: support vector machine, random forest, k-nearest neighbors and a one-layered neural network. These models are widely used in the research of automatic skin lesion diagnosis which makes them relevant to study. % Källa
Furthermore, two selection methods will be used, namely sequential forwards selection and sequential backwards selection. 

The features to be used in the feature selection are of two classes: hand-crafted and automatically generated features. The hand crafted features are based on the clinical practice through the ABCD method where a skin lesion is classified based on it’s asymmetry, border irregularity, color and diameter. The ABCD method is widely used when diagnosing skin lesions using ML due to its effectiveness and simplicity to implement. \parencite{JAIN2015735}
Thus making it relevant to the study. For the automatically generated features, SIFT was chosen as the feature. % It is relevant because … (Is it really necessary to explain why SIFT is relevant here?)

% A little bit outdated.
Lastly the base of comparison will be widened by the use of two different datasets will be used in the study, namely the HAM10000 and ISIC dataset. 

A comparison between the classifiers, where first no selection is done and then between the two selection methods, will be conducted. The result from this will then highlight whether or not different features have different impact on the efficiency and accuracy of machine learning algorithms. Furthermore, it will show if certain features are to be preferred in the context of different machine learning models. Lastly, it will show if there is any difference between the hand-crafted and automatically generated features.

\section{Scope}

The study is limited by the number of features, selection methods and models being used.

Firstly the models are limited by the fact that they consist of only machine learning. An extension of the study could include a deep learning model such as a convoluted neural network.

Secondly, the study is limited by the feature selection methods being used where only feature selection by wrapper methods are used through the sequential backward and forward selection.

Lastly, the study is limited by the features which the selection is based in three different ways. Firstly, not all combinations of the features will be examined since this would require too many computations. Secondly, the different aspects of the ABCD method can be extracted in a plethora of different ways, which leaves room for further studies. Thirdly, the features are only of two types of classes, other classes such as bag-of-features will not be used.


\chapter{Background}

\section{Skin Cancer}

% https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8705277/ bra artikel


% Lite upprepning från introduktionen ksk, men fortfarande bra att ha med
During the last  decades the frequency of malignant melanoma in Sweden has been on the rise and the trend does not seem to be going down. Yearly, approximately 60 000 persons are diagnosed with skin cancer and around 500 die from the disease. \parencite{sverige-hudcancer}

Likewise in the United States, skin cancer is the most common type of cancer to the degree that every fifth american will develop the disease at some time during their lives. The rates of melanoma have on a general trend increased, nearly doubling between 1982-2011. On some levels the rates have decreased, as in for people that are under 30. \parencite{aad-skin-cancer}

Malignant melanoma is a type of skin cancer that is the result of melano\-cyte cells in the skin starting to grow uncontrollably.
Although melanoma is a less common type of skin cancer, it is at the same time more prone to spreading to other parts of the body therefore making it more dangerous. \parencite{aad-skin-cancer}

Melanoma skin cancer has five different stages, stage 0-5, where in stage 0 the cancer is contained within the top layer of the skin while in the final stage the cancer has spread to other parts of the body \parencite{cancerresearchuk-melanoma}.
According to UK researchers the survival rate of patients diagnosed with melanoma differs greatly depending on when during the four different stages the diagnosis is made \parencite{cancerresearchuk-survival}.
Where if the cancer is detected in the first stage the survival rate is almost 100\%, however if the diagnosis is done in a later stage the survival rate drops to 30\%, although the statistic does not take into account the age of the patients. \parencite{cancerresearchuk-survival}

Recently artificial intelligence (AI) and machine learning (ML) has made great strides within dermatology in areas such as melanoma detection and classification. In one study, a machine learning algorithm was compared against experts, where the ML system outperformed the experts. \parencite{8030303}

% \subsection{Computer Aided Diagonstics} Might be a good idea to have a section about CAD, but I'm not sure if it's necessary.

\section{Machine Learning}

% https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/iet-ipr.2015.0385?sid=vendor%3Adatabase (abcd)

Machine learning (ML) is a field of computer science focusing on automated and intelligent data analysis. A ML algorithm is fed problems and answers whereupon the system tries to predict the answer. Based on the response the algorithm then makes adjustments to better give the correct answers. \parencite{das2021machine}

In the case of skin cancer detection, an ML algorithm would receive images with a ground truth for each image, meaning either the skin lesion is malignant or benign. The algorithm would then try to correctly decide if the lesion is cancerogenous thereafter the correct answer would be revealed and the algorithm makes corrections based on whether or not it was successful in the diagnosis.

An ML algorithm consists of four main steps: 1) pre-processing, 2) segmentation, 3) feature extraction and 4) classification. All of the named steps are described below.

\subsection{Pre-processing}

The main goal with pre-processing an image is to improve the quality of the picture. Improvement can be made in many ways but generally the methods can be sorted into either artifact removal or image enhancement \parencite{8377976}.
Artifact removal entails removing misleading objects in the image such as hair pixels and air bubbles which can lead to incorrect segmentation and feature extraction. Image enhancement usually consists of contrast Pre-processing is an essential step in the process since the classification is vastly dependent on the image quality. \parencite{jaworek2016automatic}

\subsection{Segmentation}

In the segmentation phase the borders of the lesion are identified. This is done to be able to identify what in the image contains the lesion. Like the pre-processing, segmentation is vital for the classification and feature extraction since parameters such as the lesion’s border cannot be correctly evaluated if the segmentation is poorly executed. At the same time, the segmentation of skin lesions is one of the most challenging steps due mainly to four reasons. Firstly, most lesions do not have a stark contrast between the healthy and unhealthy skin. Secondly, the lesion’s border may be irregular which impedes the segmentation. Thirdly, the color variegation % (huh, typ skilland)
within the lesion can be vast where multiple colors are present at the same time. Finally, there may be artifacts such as hairs or lens flare present within the image which hinders the segmentation, this is however meant to be removed during the pre-processing. \parencite{jaworek2016automatic}

\subsection{Feature Extraction}

Clinical classification is done based on the characteristics of the lesion. Likewise, the features of the lesion need to be quantified in a way that a computer can understand to make a classification. This is the goal of feature extraction, to quantify the relevant characteristics of the lesion. Which features to consider relevant depends on the base of classification, the same holds for the way to extract the features.

\subsubsection{ABCD}

The ABCD-rule is a mimic of the way clinicians determine whether or not a skin lesion is malignant or not based on four features: asymmetry, border, colour and dermoscopic structures or diameter of the lesion. The higher the asymmetry of the lesion, in terms of either shape or colour, the more likely it is to be malign. The border aspect refers to whether the border of the lesion is irregular. The lesion is divided into eight slices and for each slice, if the border is irregular a point is awarded. Regarding the colour, the lesion is scanned for the occurrence of six colours (white, red, light brown, dark brown, blue-grey and black). For each colour a point is awarded. The “D” in ABCD can either be evaluated using the dermoscopic structure or the diameter of the lesion. The dermoscopic structure is evaluated based on the presence of five structures. For each structure a point is awarded, so the values range from zero to five. If instead the diameter is evaluated, all lesions with a diameter greater than 6 mm are considered malignant and given a value of five. \parencite{smaoui2013developed} \parencite{https://doi.org/10.1049/iet-ipr.2015.0385}

\subsubsection{Scale-invariant feature transform (SIFT)}

Scale-invariant feature transform (SIFT) is a popular method to extract key points out of an image. These key points are detected by an algorithm and given descriptors based on why the points were considered important. These descriptors can then be used in a classifier.

SIFT features are, as previously mentioned, used widely in the broader image analysis field. However, the research where the features are used to classify melanoma is quite limited.

\section{Classification}

The classification of the lesions based on the features extracted can be done through several machine learning algorithms. The ones used in this study are listed below.

\subsection{Support Vector Machine (SVM)}

Support vector machines (SVM) are common and effective ML algorithms first introduced in the 1990s. SVM is an extension of the support vector classifier, which in turn is an extension of the maximal margin classifier.

The maximal margin classifier aims to separate data into two classes using a hyperplane. The support vector classifier builds on the same principle, but is more adjusted to the case when the data is not easy to separate. The SVM enlarges the feature space of the data in order to be able to separate data in a non-linear fashion. \parencite{james2013introduction}

%% TODO: Fix references from here. The book above needs paging.
% Based on: book s.340-341, 344-345, 349-354

% One very good study with accuracy of 97.5\% <- det här är en bra studie för att få ut grejer om feature extraction också, snackar om något som heter hog features

% hej vilmer testa den här länken
% hej vilmer här är en till länk
% bok att hämta sen
% bok om alla algoritmer typ 

\subsection{Random Forest (RF)}

Random forest is a tree-based method. The model consists of several decision trees taking different factors into consideration. When classifying, all individual trees try to classify the data. Then, the class that most of the trees predicted is chosen as the final classification.

% book s. 319-321
% s. 319-321

\subsection{K-Nearest Neighbors (KNN)}

K-nearest-neighbors is another method for classifying. The ground principle is to find the nearest neighboring data points from the training set for all the test data points. In a similar fashion to random forest, it performs a majority voting and then chooses the most occurring class from neighbors as the final prediction.

% book  s.39-41
% Image on p. 40 in the book

\subsection{Neural Network (NN)}

% TODO: Fix this section
Neural networks are a type of machine learning algorithm that is inspired by the human brain. The network consists of several layers of neurons, where each neuron is connected to all neurons in the previous layer. The first layer is the input layer, where the data is fed into the network. The last layer is the output layer, where the final prediction is made. The layers in between are called hidden layers. The hidden layers are the ones that do the actual work of the network. The neurons in the hidden layers are connected to all neurons in the previous layer, and the output of each neuron is calculated by a function. The output of the neurons in the last hidden layer is then fed into the output layer, where the final prediction is made.
% Detta fixade co-pilot lol

\section{Feature selection}

% https://www.jmlr.org/papers/volume3/guyon03a/guyon03a.pdf

Feature selection is a process where the different extracted features are ranked in order of importance for the results of the classification. Some features may be irrelevant and thus confusing for the model. The goal for feature selection may vary, but it is commonly used to find the most important features, features that harm the results and synergies between features. In short, reducing the number of features utilized, improves performance and accuracy. % (källa) 

In this study the greedy methods Sequential Backward Elimination (SBE) and Sequential Forward Selection (SFS) will be used.

Sequential backward selection is a process that involves multiple iterations in which a feature is eliminated during each cycle. In the initial iteration, the feature that results in the worst performance, according to some metric, when removed is excluded from the set. The process is then repeated with the updated set of features. This process is continued until the desired number of features are left. % (källa)

Forward selection shares the same underlying concept as backward selection, but instead begins with a smaller feature set and adds one feature during each iteration, resulting in an increased set of features rather than a reduced one.


\section{Related Works}

% TODO: Fix the references in this section. E.g. "Första" corresponds to a specific reference

The automatic classification of skin lesions as being either malignant or benign has been a subject of great interest and there is a plethora of publications investigating the manner. Hence, there are several studies focused around classifying lesions, using the feature set and ML models which this thesis aims to investigate. However, there is not such an abundant pool of studies which focus on feature selection methods and exploration of which types of features are the most important. 

Första studied the minimal number of necessary features for effective and accurate skin lesion classification using a KNN-model.  The features that were studies were based on the geometric (A), color (C)  and boundary (B) aspects of the ABCD rule of melanoma.(Första) A feature selection method which implemented the Sequential Backward Selection (SBS) was used. When all features (15 in total) were used, the average accuracy was around 78\%. The highest accuracy of 91\% was obtained when there were only 6, 8 and 9 features. Hence, Första showed that an effective feature selection method both improves the accuracy of the classifier as well as the computation and storage cost. Though they did not highlight which of these features were abundant and which were important to include. Additionally they only limited the study to one type of ML model, namely the KNN. 

Tre studied the effect of feature selection using the NCA method with an M-SVM on three different data sets. Like Första their method showed an increase in accuracy and runtime. However, as well as Första, they did not investigate which features were the ones leading to the increased accuracy. Furthermore, only one classifier was used with the M-SVM and therefore no results were generated using some other type of classifier. 

Fyra used ECNA feature selection to gain succesful results. The highest accuracy reached was 94.73\% using a KNN and second best was using an SVM with and accuracy of 93.83\%. They however, used deep features instead of the hand crafted features which will be used in this study.


\chapter{Methods}

\section{Machine learning methods}

\subsection{Preprocessing}

For removing artifacts such as hairs, the DullRazor® software was used. The software is created by Tim Lee, Vincent Ng, RIchard Gallagher, Andrew Coldman and David Mclean and is used frequently for preprocessing of skin lesion images. The method removes the hairs in two steps: 1) using generalized grayscale morphological closing operations, it identifies the dark hair locations, 2) verifies the shape of the hair pixels as long and thin, whereafter it replaces the verified pixels by bilinear interpolation and lastly 3) smooths the replaced hair pixels. % (källa)

% TODO: Download and insert the images from the google drive

\subsection{Segmentation}

The aim of this study was not to develop a new segmentation method, but rather to compare the effect of different feature selection methods on the accuracy of the classification. Therefore, the segmentation was done using open-source software published by [name] availible on GitHub.

\subsection{Feature extraction}

As mentioned in the background, the two feature extraction methods used were ABCD and SIFT.

\subsubsection{ABCD}

The ABCD features were extracted using the open-source software published by [name] availible on GitHub. The software extracts the features based on the method proposed in [this] study. % Källa

% TODO: Dubbelkolla namn på library
To calculate the asymmetry and border features the measure library from sci-kit is used, with the \verb|get_region_props| function. The color features are calculated using the color library from sci-kit.

% TODO: Lägg in hur man beräknar grejerna

% Hur de beräknas
% github repot

\subsubsection{SIFT}

The SIFT features are extracted using the OpenCV class SIFT which implements the algorithm by David G. Lowe. %(källa1) (källa).
After that...

% Vilket bibliotek
% opencv

\subsection{Classification}

All classifiers used in this study are from the Scikit-sklearn library which is a free-to-use library for machine learning in Python.% (källa)

% Nedanstående stämmer typ inte längre. Ska vi skriva något om parameter sweep? Vi gjorde ju lite.
Although all ML models’ parameters can be fine-tuned to optimize performance and run-time, the default parameters will be used since it is not the aim of the study to create an optimal implementation. The focus is instead on the feature selection’s effect on the performance of the classifiers.

% (källa ?)

\section{Dataset}

The dataset used in this study is a variant of the one produced by the ISIC Archive. The difference with the original one is that the one used only has two classes: Malignant and Benign. The dataset contains around 3400 images, each being 224x224 pixels. The dataset is balanced, which has positive effects on the classifiers accuracy. The larger, but unbalanced, HAM10000 dataset was also considered. However, during initial testing it was discovered that the balanced dataset resulted in a better accuracy. It was also easier to work with the balanced dataset, as it already only had two classes while HAM10000 has 7.

The dataset was downloaded and structured in order to have every image in the same folder. In order to store the ground truth information indicating whether a given image is malignant or benign, a one-dimensional array was created storing boolean values.

\section{Metrics}

\subsection{Accuracy (Balanced accuracy)}

Accuracy is a metric which is widely used and simple to calculate.  
It is calculated by dividing the total number of correctly classified images with the total number of images. 
It therefore measures the probability that the model will classify a given random image correctly. källa  

Accuracy was the metric used to determine the performance of the classifiers and the effect of the feature selection methods.
 % källa  

% ! We do not use balanced atm so maybe remove.


\section{Feature selection}

All feature selection methods used in the study originates from the \verb|Scikit-sklearn| library \verb|feature_selection|.


The manner in which the feature  selection was performed differs slightly due to the selection method employed. For the SFS, the feature set was initially empty. The method then adds all features, one at a time. For the SBE the feature set at first contained all features, whereupon features were removed one at a time, until the feature set consisted of only one feature. In each iteration, the accuracy and which features constituted the feature set were recorded. 
This process was repeated five times for every selection method and classifier. Hence, 40 tests were conducted in total.
% TODO: Write that we did the tests five times for each classifier and feature selection method

\section{Evaluation}

The method for evaluating the three different research questions are stated below.

\subsection{Is there a difference between different models concerning which features are most effective?}
Furthermore, since in every iteration of the selection methods, the included features were recorded, the features included in the feature set generating the optimal accuracy was determined. Onwards, this feature set will be referred to as the optimal feature set. 

Based on this statistic, the probability that a feature would be included in the optimal feature set, was calculated by dividing the number of times the feature was included in the optimal feature set with the number of tests performed. The features with the highest probability can therefore be seen as the most important.

\subsection{Which features and combinations of features are the most important in terms of classification accuracy?}
Based on the findings from the previous research question, the results were summarized to give insight on a more general level where the occurrences of each feature in the optimal feature set was divided by the total number of tests performed. This gives an insight into which features are most likely to constitute the optimal feature regardless of the classifier.

\subsection{Are some feature selection methods more efficient in creating better accuracy than others? Which one uses the fewest features?}
Since multiple tests were performed for every combination of classifier and selection method, it becomes possible to calculate the average accuracy for each number of features in the feature space. Hence the highest average accuracy and the expected number of features needed to achieve this accuracy can be determined. To determine which selection model is the most efficient, the difference between the original accuracy and the highest average accuracy using feature selection, was examined.


% !Observera att detta troligen är utdaterat





\chapter{Results}
Placeholder reference in order to test the bibliography: \parencite{einstein2016}

\section{Determining important features for models}

\section{Determining most important features}

\section{Difference between selection methods}


And then textcite: \textcite{einstein2016}
\blindtext

\chapter{Discussion}
\blindtext

\chapter{Conclusions}
\blindtext

% Print the bibliography (and make it appear in the table of contents)
\printbibliography[heading=bibintoc]

\appendix

\chapter{Something Extra}

% Tailmatter inserts the back cover page (if enabled)
\tailmatter

\end{document}
